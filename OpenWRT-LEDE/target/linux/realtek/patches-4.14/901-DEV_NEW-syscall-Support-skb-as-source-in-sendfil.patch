From d3b7f2e3d8cd0745e92301e0a0946c4ec44eb9f9 Mon Sep 17 00:00:00 2001
Date: Thu, 29 Jun 2017 16:46:09 +0800
Subject: [PATCH] [DEV_NEW]syscall: Support skb as source in sendfil

1. Improve NAS write performance on data copy from socket to file.
2. Only support EXT4 file system.
3. Modified for kernel 4.4
- Fix patch failure and include API change after following commit:
-- commit 5fa8e0a: fs: Rename file_remove_suid() to file_remove_privs()
4. Limit per sendfile syscall to 256KB
5. Add per-page write support
- Default to call per-page call on unsupported file system
- Remove multi-page support for ecryptfs
- Only support multi-page sendfile in ext4
- Check write_begin/write_end operations before execution
-- Don't support Btrfs
6. Fix call trace on ftpget transfer
- Handling sendfile from socket without offset
7. Modify for Linux 4.9
- Use i_rwsem instead of i_mutex

Change-Id: I290f75a79cb08681c1cb850bdc16b2fb54552670
---
 drivers/soc/realtek/Kconfig |  11 +
 fs/ext4/file.c              |   3 +
 fs/read_write.c             |  38 +++
 fs/splice.c                 | 486 ++++++++++++++++++++++++++++++++++++
 include/linux/fs.h          |  17 ++
 include/linux/skbuff.h      |   4 +
 include/linux/socket.h      |   5 +
 include/linux/splice.h      |   9 +
 net/ipv4/tcp.c              |  24 ++
 9 files changed, 597 insertions(+)

diff --git a/drivers/soc/realtek/Kconfig b/drivers/soc/realtek/Kconfig
index 236dd5caf..57db59e2e 100644
--- a/drivers/soc/realtek/Kconfig
+++ b/drivers/soc/realtek/Kconfig
@@ -1,3 +1,14 @@
+menu "Realtek NAS support"
+	depends on RTK_PLATFORM
+
+config SENDFILE_PATCH
+	bool "Reverse sendfile patch"
+	default n
+	help
+	Use patched sendfile syscall to improve write performance on NAS.
+
+endmenu
+
 config RTD139x
 	bool "Realtek RTD139x SoC family specific drivers"
 	depends on ARCH_RTD139x
diff --git a/fs/ext4/file.c b/fs/ext4/file.c
index 1913c6949..62bccb7fb 100644
--- a/fs/ext4/file.c
+++ b/fs/ext4/file.c
@@ -725,6 +725,9 @@ const struct file_operations ext4_file_operations = {
 	.get_unmapped_area = thp_get_unmapped_area,
 	.splice_read	= generic_file_splice_read,
 	.splice_write	= iter_file_splice_write,
+#if defined(CONFIG_SENDFILE_PATCH)
+	.splice_from_socket = generic_splice_from_socket,
+#endif
 	.fallocate	= ext4_fallocate,
 };
 
diff --git a/fs/read_write.c b/fs/read_write.c
index 5a78420c4..7db7e5e1e 100644
--- a/fs/read_write.c
+++ b/fs/read_write.c
@@ -24,6 +24,9 @@
 
 #include <linux/uaccess.h>
 #include <asm/unistd.h>
+#ifdef CONFIG_SENDFILE_PATCH
+#include <net/sock.h>
+#endif /* CONFIG_SENDFILE_PATCH */
 
 const struct file_operations generic_ro_fops = {
 	.llseek		= generic_file_llseek,
@@ -1369,6 +1372,11 @@ COMPAT_SYSCALL_DEFINE6(pwritev2, compat_ulong_t, fd,
 
 #endif
 
+#ifdef CONFIG_SENDFILE_PATCH
+extern ssize_t generic_splice_from_socket(struct file *file, struct socket *sock,
+		loff_t *ppos, size_t count, bool ppage);
+#endif
+
 static ssize_t do_sendfile(int out_fd, int in_fd, loff_t *ppos,
 		  	   size_t count, loff_t max)
 {
@@ -1379,6 +1387,36 @@ static ssize_t do_sendfile(int out_fd, int in_fd, loff_t *ppos,
 	ssize_t retval;
 	int fl;
 
+#ifdef CONFIG_SENDFILE_PATCH
+	/* check if in_fd is a socket */
+	int error;
+	struct socket *sock = NULL;
+
+	error = -EBADF;
+	sock = sockfd_lookup(in_fd, &error);
+	if (sock) {
+		if (!sock->sk)
+			goto done;
+		out = fdget(out_fd);
+
+		if (out.file) {
+			if (!(out.file->f_mode & FMODE_WRITE))
+				goto done;
+			// Default to use generic splice
+			if (out.file->f_op->splice_from_socket)
+				error = (int)out.file->f_op->splice_from_socket(out.file, sock, ppos, count, false);
+			else
+				//goto done;
+				error = (int)generic_splice_from_socket(out.file, sock, ppos, count, true);
+		}
+done:
+		if(out.file)
+			fdput(out);
+		fput(sock->file);
+		return (ssize_t)error;
+	}
+#endif
+
 	/*
 	 * Get input file, and verify that it is ok..
 	 */
diff --git a/fs/splice.c b/fs/splice.c
index 00d2f142d..21519c630 100644
--- a/fs/splice.c
+++ b/fs/splice.c
@@ -36,6 +36,18 @@
 #include <linux/sched/signal.h>
 
 #include "internal.h"
+#if defined(CONFIG_SENDFILE_PATCH)
+#include <net/sock.h>
+#include <linux/net.h>
+#include <linux/socket.h>
+#include <linux/genalloc.h>
+#include <linux/backing-dev.h>
+#include <linux/version.h>
+
+struct common_mempool;
+static struct common_mempool/*struct gen_pool*/ * rcv_pool = NULL;
+static struct common_mempool/*struct gen_pool*/ * kvec_pool = NULL;
+#endif
 
 /*
  * Attempt to steal a page from a pipe buffer. This should perhaps go into
@@ -1185,6 +1197,458 @@ static long do_splice(struct file *in, loff_t __user *off_in,
 	return -EINVAL;
 }
 
+#if defined(CONFIG_SENDFILE_PATCH)
+/****************************** POOL MANAGER *************************************/
+/* Forward declarations */
+typedef struct common_mempool common_mempool_t;
+void* common_mempool_alloc(common_mempool_t* pool);
+void common_mempool_free(common_mempool_t* pool, void* mem);
+common_mempool_t* common_mempool_get(void* mem);
+common_mempool_t*  common_mempool_create(uint32_t number_of_entries, uint32_t entry_size);
+void  common_mempool_destroy(common_mempool_t* pool);
+int32_t common_mempool_get_number_of_free_entries(common_mempool_t* pool);
+int32_t common_mempool_get_number_of_entries(common_mempool_t* pool);
+int32_t common_mempool_get_entry_size(common_mempool_t* pool);
+
+/* Implementation */
+#define COMMON_MPOOL_HDR_FLAGS_ALLOCATED 0x00000001
+#define COMMON_MPOOL_HDR_MAGIC           0xa5a5a508
+#define COMMON_MPOOL_FTR_MAGIC           0xa5a5a509
+#define COMMON_MPOOL_ALIGN4(size) ((size)+4) & 0xFFFFFFFC;
+#define COMMON_MPOOL_CHECK_ALIGNED4(ptr) ((((uint64_t)(ptr)) & 0x00000003) == 0)
+
+typedef struct common_mpool_hdr
+{
+	struct common_mpool_hdr* next;
+	common_mempool_t*        pool;
+	uint32_t flags;
+	uint32_t magic;
+} common_mpool_hdr_t;
+
+typedef struct
+{
+	uint32_t magic;
+	common_mempool_t* pool;
+} common_mpool_ftr_t;
+
+struct common_mempool
+{
+	common_mpool_hdr_t*  head;
+	common_mpool_hdr_t*  tail;
+	uint32_t		number_of_free_entries;
+	spinlock_t		lock;
+	uint32_t		data_size; /* size of data section in pool entry */
+	uint32_t		pool_entry_size; /* size of pool entry */
+	/* parameters passed on init */
+	uint32_t		number_of_entries;
+	uint32_t		entry_size;
+	uint8_t*		mem;
+};
+
+bool common_mempool_check_internal(common_mempool_t * pool,
+                                          void * ptr,
+                                          common_mpool_hdr_t * hdr,
+                                          common_mpool_ftr_t * ftr)
+{
+	if (!ptr) {
+		printk(KERN_ERR "illegal ptr NULL");
+		return false;
+	}
+
+	if (!COMMON_MPOOL_CHECK_ALIGNED4(ptr)) {
+		printk(KERN_ERR "ptr not aligned %p",ptr);
+		return false;
+	}
+
+	if (hdr->magic != COMMON_MPOOL_HDR_MAGIC) {
+		printk(KERN_ERR "illegal hdr magic %x for ptr %p",hdr->magic,ptr);
+		return false;
+	}
+
+	if (ftr->magic != COMMON_MPOOL_FTR_MAGIC) {
+		printk(KERN_ERR "illegal ftr magic %x for ptr %p",ftr->magic,ptr);
+		return false;
+	}
+
+	if (hdr->pool != pool || ftr->pool != pool) {
+		printk(KERN_ERR "inconsistent size hdr->pool: %p ftr->pool: %p for ptr %p",hdr->pool,ftr->pool,ptr);
+		return false;
+	}
+
+	if (!(hdr->flags & COMMON_MPOOL_HDR_FLAGS_ALLOCATED)) {
+		printk(KERN_ERR "ptr %p was not allocated",ptr);
+		return false;
+	}
+	return true;
+}
+
+void* common_mempool_alloc(common_mempool_t* pool)
+{
+	common_mpool_hdr_t* hdr;
+
+	if (!pool || !pool->head || pool->number_of_free_entries == 0) {
+		return NULL;
+	}
+	spin_lock_bh(&pool->lock);
+	hdr = pool->head;
+	pool->head = pool->head->next;
+
+	if (!pool->head) {
+		pool->tail = NULL;
+	}
+
+	hdr->flags = COMMON_MPOOL_HDR_FLAGS_ALLOCATED;
+	pool->number_of_free_entries--;
+	spin_unlock_bh(&pool->lock);
+	return ((uint8_t*)hdr+sizeof(common_mpool_hdr_t));
+}
+
+void common_mempool_free(common_mempool_t* pool, void* ptr)
+{
+	common_mpool_hdr_t* hdr;
+	common_mpool_ftr_t* ftr;
+
+	if (!pool || !ptr) {
+		return;
+	}
+	if (!COMMON_MPOOL_CHECK_ALIGNED4(ptr)) {
+		printk(KERN_ERR "ptr not aligned %p",ptr);
+		return;
+	}
+	spin_lock_bh(&pool->lock);
+	hdr = (common_mpool_hdr_t*)((uint8_t*)ptr-sizeof(common_mpool_hdr_t));
+	ftr = (common_mpool_ftr_t*)((uint8_t*)ptr+pool->data_size);
+
+	if (!common_mempool_check_internal(pool,ptr,hdr,ftr)) {
+		printk(KERN_ERR "invalid ptr %p",ptr);
+		spin_unlock_bh(&pool->lock);
+		return;
+	}
+
+	hdr->flags ^= COMMON_MPOOL_HDR_FLAGS_ALLOCATED;
+	hdr->next = NULL;
+
+	if (!pool->head) {
+		pool->head = pool->tail = hdr;
+	} else {
+		pool->tail->next = hdr;
+		pool->tail = hdr;
+	}
+
+	pool->number_of_free_entries++;
+	spin_unlock_bh(&pool->lock);
+}
+
+common_mempool_t*  common_mempool_create(uint32_t number_of_entries,
+						uint32_t entry_size)
+{
+	uint32_t i;
+	uint32_t aligned_entry_size;
+	uint32_t pool_entry_size;
+	common_mpool_hdr_t* hdr;
+	common_mpool_hdr_t* next_hdr;
+	common_mpool_ftr_t* ftr;
+	common_mempool_t* pool;
+
+	aligned_entry_size = COMMON_MPOOL_ALIGN4(entry_size);
+	pool_entry_size = COMMON_MPOOL_ALIGN4(sizeof(common_mpool_hdr_t)+aligned_entry_size+sizeof(common_mpool_ftr_t));
+	pool = kmalloc((sizeof(common_mempool_t) + pool_entry_size*number_of_entries), GFP_ATOMIC);
+
+	if (!pool) {
+		return NULL;
+	}
+
+	pool->entry_size = entry_size;
+	pool->number_of_entries = number_of_entries;
+	pool->data_size  = aligned_entry_size;
+	pool->pool_entry_size = pool_entry_size;
+	pool->number_of_free_entries = number_of_entries;
+	pool->mem = (uint8_t*)(pool+1);
+	pool->head = (common_mpool_hdr_t*)pool->mem;
+	spin_lock_init(&pool->lock);
+
+	for (i=0;i<number_of_entries;i++) {
+		hdr = (common_mpool_hdr_t*)&pool->mem[pool_entry_size*i];
+		ftr = (common_mpool_ftr_t*)((uint8_t*)hdr+sizeof(common_mpool_hdr_t)+aligned_entry_size);
+		hdr->magic = COMMON_MPOOL_HDR_MAGIC;
+		hdr->pool = pool;
+		hdr->flags = 0;
+		ftr->magic = COMMON_MPOOL_FTR_MAGIC;
+		ftr->pool = pool;
+
+		if (i < (number_of_entries-1)) {
+			next_hdr = (common_mpool_hdr_t*)&pool->mem[pool_entry_size*(i+1)];
+		} else {
+			pool->tail = hdr;
+			next_hdr = NULL;
+		}
+
+		hdr->next = next_hdr;
+	}
+	return pool;
+}
+
+void  common_mempool_destroy(common_mempool_t* pool)
+{
+	if (!pool) {
+		return;
+	}
+
+	kfree(pool);
+}
+
+int32_t common_mempool_get_number_of_free_entries(common_mempool_t* pool)
+{
+	if (!pool) {
+		return -1;
+	}
+
+	return (int32_t)pool->number_of_free_entries;
+}
+
+int32_t common_mempool_get_number_of_entries(common_mempool_t* pool)
+{
+	if (!pool) {
+		return -1;
+	}
+	return (int32_t)pool->number_of_entries;
+}
+
+int32_t common_mempool_get_entry_size(common_mempool_t* pool)
+{
+	if (!pool) {
+		return -1;
+	}
+	return (int32_t)pool->entry_size;
+}
+
+common_mempool_t* common_mempool_get(void* ptr)
+{
+	common_mpool_hdr_t* hdr;
+	common_mpool_ftr_t* ftr;
+
+	if (!ptr) {
+		return NULL;
+	}
+	if (!COMMON_MPOOL_CHECK_ALIGNED4(ptr)) {
+		return NULL;
+	}
+	hdr = (common_mpool_hdr_t*)((uint8_t*)ptr-sizeof(common_mpool_hdr_t));
+	ftr = (common_mpool_ftr_t*)((uint8_t*)ptr + hdr->pool->data_size);
+
+	if (hdr->magic != COMMON_MPOOL_HDR_MAGIC) {
+		printk(KERN_ERR "illegal hdr magic %x for ptr %p",hdr->magic,ptr);
+		return NULL;
+	}
+	if (ftr->magic != COMMON_MPOOL_FTR_MAGIC) {
+		printk(KERN_ERR "illegal ftr magic %x for ptr %p",ftr->magic,ptr);
+		return NULL;
+	}
+	if (hdr->pool != ftr->pool || !hdr->pool) {
+		printk(KERN_ERR "inconsistent size hdr->pool: %p ftr->pool: %p for ptr %p",hdr->pool,ftr->pool,ptr);
+		return false;
+	}
+	return hdr->pool;
+}
+/****************************** POOL MANAGER *************************************/
+
+ssize_t generic_splice_from_socket(struct file *file, struct socket *sock,
+				     loff_t *ppos, size_t count, bool ppage)
+				     //loff_t __user *ppos, size_t count)
+{
+	struct address_space *mapping = file->f_mapping;
+	struct inode *inode = mapping->host;
+	loff_t pos;
+	size_t count_total = 0;
+	size_t pcount;
+	size_t count_tmp;
+	int err = 0;
+	int i = 0;
+	int nr_pages = 0;
+	int page_cnt_est= count/PAGE_SIZE + 1;
+	struct recvfile_ctl_blk *rv_cb = NULL;
+	struct kvec *iov = NULL;
+	struct msghdr msg;
+	long rcvtimeo;
+	int ret;
+	struct kiocb iocb;
+	struct iov_iter from;
+
+	//if (copy_from_user(&pos, ppos, sizeof(loff_t)))
+	//	return -EFAULT;
+	if (!ppos) {
+		pos = sock->file->f_pos;
+	} else {
+		pos = *ppos;
+	}
+
+	if (!mapping->a_ops->write_begin || !mapping->a_ops->write_end) {
+		return -EBADF;
+	}
+
+	if (count > MAX_SIZE_PER_RECVFILE) {
+		printk("%s: count(%zu) exceeds maxinum\n", __func__, count);
+		return -EINVAL;
+	}
+
+	init_sync_kiocb(&iocb, file);
+	iocb.ki_pos = pos;
+	memset((void*)&from, 0, sizeof(struct iov_iter));
+	from.count = count;
+	from.type |= WRITE;
+
+	down_write(&inode->i_rwsem);
+
+	sb_start_write(inode->i_sb);
+
+	/* We can write back this queue in page reclaim */
+	current->backing_dev_info = inode_to_bdi(inode);
+
+	err = generic_write_checks(&iocb, &from);
+	//if (err != 0 || count == 0)
+	if (err <= 0)
+		goto done;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 2, 0)
+	file_remove_privs(file);
+#else
+	file_remove_suid(file);
+#endif
+	file_update_time(file);
+
+	if (unlikely(!rcv_pool || !kvec_pool))
+	{
+		printk(KERN_ERR "rcv_pool %p kvec_pool %p uninitialized\n", rcv_pool, kvec_pool);
+		sb_end_write(inode->i_sb);
+		return -ENOMEM;
+	}
+
+	rv_cb = (struct recvfile_ctl_blk *)common_mempool_alloc(rcv_pool);
+	iov = (struct kvec *)common_mempool_alloc(kvec_pool);
+
+	if (!rv_cb || !iov)
+	{
+		printk(KERN_ERR "Failed to get pool mem for %d pages (rv_cb %p iov %p)\n", page_cnt_est, rv_cb, iov);
+		sb_end_write(inode->i_sb);
+		return -ENOMEM;
+	}
+
+	/* Calculate first write size within page */
+	if (ppage)
+	{
+		pcount  = PAGE_SIZE - (pos & (PAGE_SIZE - 1));
+		if (pcount > count)
+			pcount = count;
+	}
+	else
+	{
+		pcount = count;
+	}
+
+	count_total = 0;
+	count_tmp = pcount;
+	for(;count_total < count; nr_pages=0,count_total+=count_tmp,count_tmp=pcount=(count-count_total<PAGE_SIZE)?(count-count_total):PAGE_SIZE){
+		do {
+			unsigned long bytes;	/* Bytes to write to page */
+			unsigned long offset;	/* Offset into pagecache page */
+			struct page *pageP;
+			void *fsdata;
+
+			offset = (pos & (PAGE_SIZE - 1));
+			bytes = PAGE_SIZE - offset;
+			if (bytes > count_tmp)
+				bytes = count_tmp;
+			ret = mapping->a_ops->write_begin(file, mapping, pos, bytes,
+							  0, &pageP, &fsdata);
+
+			if (unlikely(ret)) {
+				err = ret;
+				goto cleanup;
+			}
+
+			rv_cb[nr_pages].rv_page = pageP;
+			rv_cb[nr_pages].rv_pos = pos;
+			rv_cb[nr_pages].rv_count = bytes;
+			rv_cb[nr_pages].rv_fsdata = fsdata;
+			iov[nr_pages].iov_base = kmap(pageP) + offset;
+			iov[nr_pages].iov_len = bytes;
+			nr_pages++;
+			count_tmp -= bytes;
+			pos += bytes;
+		} while (count_tmp);
+
+		/* IOV is ready, receive the date from socket now */
+		msg.msg_name = NULL;
+		msg.msg_namelen = 0;
+		msg.msg_control = NULL;
+		msg.msg_controllen = 0;
+		msg.msg_flags = MSG_KERNSPACE;
+		rcvtimeo = sock->sk->sk_rcvtimeo;
+		sock->sk->sk_rcvtimeo = 8 * HZ;
+
+		ret = kernel_recvmsg(sock, &msg, &iov[0], nr_pages, pcount,
+				     MSG_WAITALL | MSG_NOCATCHSIGNAL);
+
+		sock->sk->sk_rcvtimeo = rcvtimeo;
+		if(ret != pcount)
+			err = -EPIPE;
+		else
+			err = 0;
+
+		if (unlikely(err < 0)) {
+			goto cleanup;
+		}
+
+		for(i=0,count_tmp=0;i < nr_pages; i++) {
+			kunmap(rv_cb[i].rv_page);
+			ret = mapping->a_ops->write_end(file, mapping,
+							rv_cb[i].rv_pos,
+							rv_cb[i].rv_count,
+							rv_cb[i].rv_count,
+							rv_cb[i].rv_page,
+							rv_cb[i].rv_fsdata);
+			if (unlikely(ret < 0))
+				printk("%s: write_end fail,ret = %d\n", __func__, ret);
+			count_tmp += rv_cb[i].rv_count;
+		}
+
+		if (count_tmp != pcount)
+		{
+			printk(KERN_ERR "%s: Mismatch in write begin/end! begin count:%zu, end count:%zu\n", __func__, pcount, count_tmp);
+			//break; // break??
+		}
+        } // Per-page write call
+	balance_dirty_pages_ratelimited(mapping);
+	//if (copy_to_user(ppos, &pos, sizeof(loff_t)))
+	//	err = -EFAULT;
+	if (ppos) {
+		*ppos = pos;
+	} else {
+		sock->file->f_pos = pos;
+	}
+done:
+	current->backing_dev_info = NULL;
+	common_mempool_free(rcv_pool, (void*)rv_cb);
+	common_mempool_free(kvec_pool, (void*)iov);
+
+	up_write(&inode->i_rwsem);
+	sb_end_write(inode->i_sb);
+	return err ? err : count_total;
+cleanup:
+	for(i = 0; i < nr_pages; i++) {
+		kunmap(rv_cb[i].rv_page);
+		ret = mapping->a_ops->write_end(file, mapping,
+						rv_cb[i].rv_pos,
+						rv_cb[i].rv_count,
+						rv_cb[i].rv_count,
+						rv_cb[i].rv_page,
+						rv_cb[i].rv_fsdata);
+	}
+
+	goto done;
+}
+#endif
+
 static int iter_to_pipe(struct iov_iter *from,
 			struct pipe_inode_info *pipe,
 			unsigned flags)
@@ -1747,3 +2211,25 @@ SYSCALL_DEFINE4(tee, int, fdin, int, fdout, size_t, len, unsigned int, flags)
 
 	return error;
 }
+
+#if defined(CONFIG_SENDFILE_PATCH)
+static int __init init_splice_pools(void)
+{
+	unsigned int rcv_pool_size= sizeof(struct recvfile_ctl_blk) * (MAX_PAGES_PER_RECVFILE+1);
+	unsigned int kve_pool_size= sizeof(struct kvec) * (MAX_PAGES_PER_RECVFILE+1);
+
+	rcv_pool =  common_mempool_create((8 * num_possible_cpus()), rcv_pool_size);
+	kvec_pool = common_mempool_create((8 * num_possible_cpus()), kve_pool_size);
+	if (!rcv_pool || !kvec_pool)
+	{
+		return -ENOMEM;
+	}
+/*
+	printk(KERN_ERR "%s rcv %p (sz:%d) kvec %p (sz:%d) per %d core\n",
+		__FUNCTION__, rcv_pool, rcv_pool_size, kvec_pool, kve_pool_size, num_possible_cpus());
+*/
+	return 0;
+}
+
+fs_initcall(init_splice_pools);
+#endif
diff --git a/include/linux/fs.h b/include/linux/fs.h
index c62a079fb..801418103 100644
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -54,6 +54,9 @@ struct vm_area_struct;
 struct vfsmount;
 struct cred;
 struct swap_info_struct;
+#ifdef CONFIG_SENDFILE_PATCH
+struct socket;
+#endif
 struct seq_file;
 struct workqueue_struct;
 struct iov_iter;
@@ -1725,6 +1728,11 @@ struct file_operations {
 	int (*flock) (struct file *, int, struct file_lock *);
 	ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int);
 	ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int);
+#ifdef CONFIG_SENDFILE_PATCH
+	ssize_t (*splice_from_socket)(struct file *, struct socket *,
+			loff_t *ppos, size_t count, bool ppage);
+			//loff_t __user *ppos, size_t count);
+#endif
 	int (*setlease)(struct file *, long, struct file_lock **, void **);
 	long (*fallocate)(struct file *file, int mode, loff_t offset,
 			  loff_t len);
@@ -2932,6 +2940,11 @@ extern ssize_t generic_file_write_iter(struct kiocb *, struct iov_iter *);
 extern ssize_t generic_file_direct_write(struct kiocb *, struct iov_iter *);
 extern ssize_t generic_perform_write(struct file *, struct iov_iter *, loff_t);
 
+#ifdef CONFIG_SENDFILE_PATCH
+#define MAX_SIZE_PER_RECVFILE 256*1024
+#define MAX_PAGES_PER_RECVFILE MAX_SIZE_PER_RECVFILE/PAGE_SIZE
+#endif
+
 ssize_t vfs_iter_read(struct file *file, struct iov_iter *iter, loff_t *ppos,
 		rwf_t flags);
 ssize_t vfs_iter_write(struct file *file, struct iov_iter *iter, loff_t *ppos,
@@ -2954,6 +2967,10 @@ extern ssize_t generic_splice_sendpage(struct pipe_inode_info *pipe,
 extern long do_splice_direct(struct file *in, loff_t *ppos, struct file *out,
 		loff_t *opos, size_t len, unsigned int flags);
 
+#ifdef CONFIG_SENDFILE_PATCH
+extern ssize_t generic_splice_from_socket(struct file *file, struct socket *sock,
+					loff_t *ppos, size_t count, bool ppage);
+#endif
 
 extern void
 file_ra_state_init(struct file_ra_state *ra, struct address_space *mapping);
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 3172e14d9..447d11ef8 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -3280,6 +3280,10 @@ unsigned int datagram_poll(struct file *file, struct socket *sock,
 			   struct poll_table_struct *wait);
 int skb_copy_datagram_iter(const struct sk_buff *from, int offset,
 			   struct iov_iter *to, int size);
+#ifdef CONFIG_SENDFILE_PATCH
+int skb_copy_datagram_iter1(const struct sk_buff *from, int offset,
+			   struct iov_iter *to, int size);
+#endif
 static inline int skb_copy_datagram_msg(const struct sk_buff *from, int offset,
 					struct msghdr *msg, int size)
 {
diff --git a/include/linux/socket.h b/include/linux/socket.h
index 9286a5a8c..8bc2010d3 100644
--- a/include/linux/socket.h
+++ b/include/linux/socket.h
@@ -293,6 +293,11 @@ struct ucred {
 #define MSG_CMSG_CLOEXEC 0x40000000	/* Set close_on_exec for file
 					   descriptor received through
 					   SCM_RIGHTS */
+#ifdef CONFIG_SENDFILE_PATCH
+#define MSG_KERNSPACE		0x40000
+#define MSG_NOCATCHSIGNAL	0x80000
+#endif
+
 #if defined(CONFIG_COMPAT)
 #define MSG_CMSG_COMPAT	0x80000000	/* This message needs 32 bit fixups */
 #else
diff --git a/include/linux/splice.h b/include/linux/splice.h
index 74b4911ac..beb0ae042 100644
--- a/include/linux/splice.h
+++ b/include/linux/splice.h
@@ -44,6 +44,15 @@ struct splice_desc {
 	bool need_wakeup;		/* need to wake up writer */
 };
 
+#if defined(CONFIG_SENDFILE_PATCH)
+struct recvfile_ctl_blk {
+	struct page *rv_page;
+	loff_t rv_pos;
+	size_t rv_count;
+	void *rv_fsdata;
+};
+#endif
+
 struct partial_page {
 	unsigned int offset;
 	unsigned int len;
diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c
index 00ae9a1d4..0a302f8ab 100644
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@ -1818,6 +1818,25 @@ int tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int nonblock,
 	do {
 		u32 offset;
 
+#ifdef CONFIG_SENDFILE_PATCH
+		if(flags &  MSG_NOCATCHSIGNAL) {
+			if (signal_pending(current)) {
+				if (sigismember(&current->pending.signal, SIGQUIT) ||
+					sigismember(&current->pending.signal, SIGABRT) ||
+					sigismember(&current->pending.signal, SIGKILL) ||
+					sigismember(&current->pending.signal, SIGTERM) ||
+					sigismember(&current->pending.signal, SIGSTOP) ) {
+
+					printk("%s (%d) Avoiding recvfile() hangs.\n", __FILE__, __LINE__);
+					if (copied)
+						break;
+					copied = timeo ? sock_intr_errno(timeo) : -EAGAIN;
+					break;
+				}
+			}
+		}
+        else
+#endif
 		/* Are we at urgent data? Stop if we have read anything or have SIGURG pending. */
 		if (tp->urg_data && tp->urg_seq == *seq) {
 			if (copied)
@@ -1873,6 +1892,11 @@ int tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int nonblock,
 				break;
 
 			if (sk->sk_err) {
+#ifdef CONFIG_SENDFILE_PATCH
+				if ( (msg->msg_flags == MSG_KERNSPACE) &&
+					ECONNRESET == sk->sk_err )
+					printk("connection reset by peer.\n");
+#endif
 				copied = sock_error(sk);
 				break;
 			}
-- 
2.17.1

